{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Linear Classifier on Cifar-10\n",
    "\n",
    "We will be training a linear classifier, using the famed [cifar-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html), so that our  model can classify pictures of cars, planes, cats, dogs, frogs, and other items.\n",
    "\n",
    "Our linear classifier did not use regularization, and simply had a learning rate of 1. Unlike our work with the  spiral dataset, these hyper-parameters - those parameters that impact our model but **do not** get updated during training - will not be so trivial.\n",
    "\n",
    "We will need to use a validation dataset to find decent values for our regularization and learning rate.\n",
    "\n",
    "Lastly, we will depict what our model's weights ultimately learned, and reaffirm our intuition that the columns of $W$ become \"canonical representations of the classes being identified. In simpler terms: one column of $W$ will look like the \"average\" car. Another, the \"average\" frog. Etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 Data Loading and Preprocessing\n",
    "Import `datasets` and import the function that loads cifar-10.\n",
    "\n",
    "Load the cifar-10 dataset and print out the shapes of the training/testing data/labels, as well as the classification categories for cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "x_train, y_train, x_test, y_test, labels = <....>\n",
    "\n",
    "print('Training data shape: ', x_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the contents of y_train. Use the following code to plot the 0th image in the training data set.\n",
    "```python\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(x_train[0].astype('uint8'))\n",
    "```\n",
    "Use `y_train` and `labels` to confirm that the labels match with the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some example images contained in cifar-10. Run the following cell to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(x_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Split\" the training data and labels so that the first 49,000 pieces of data/labels are in the training set (`x_train` and `y_train`), and the last 1,000 are in the validation set (`x_val` and `y_val`). You can do this easily using slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "print('Train data shape: ', x_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', x_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the shapes of these arrays. Just like how our spiral data had a shape of $(N, 2)$, since each datum had two features (x-coord and y-coord), we want our data to be shaped like a 2D array also so that we can use matrix multiplication.\n",
    "\n",
    "We want to reshape our data from $(N, 32, 32, 3) \\rightarrow (N, D)$. What is the value for $D$? By reshaping our data this way, we are simply \"flattening out our pixels\"\n",
    "\n",
    "```\n",
    "  [[[R0, G0, B0], [R1,G1,B1], [R2,G2,B2]]\n",
    "   [[R3, G3, B3], [R4,G4,B4], [R5,G5,B5]]\n",
    "   ...\n",
    "```\n",
    "Becomes\n",
    "```\n",
    "[R0, G0, B0, R1, B1, G1, ..., Rn, Bn, Gn]\n",
    "```\n",
    "We can thus think of the image as being a point in a \"D-dimensional\" space: $\\mathbb{R}^{D}$\n",
    "\n",
    "Reshape your train, test, and validation data to be 2D arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# As a sanity check, print out the shapes of the data\n",
    "print('Training data shape: ', x_train.shape)\n",
    "print('Validation data shape: ', x_val.shape)\n",
    "print('Test data shape: ', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important preprocessing step involves \"centering\" the data around 0, so that there are not a problem of our model's numbers \"drifting\" away, and getting too big.\n",
    "\n",
    "Compute the \"mean training image\". That is, take the mean of `x_train` over axis-0: $(N, D) \\rightarrow (D,)$\n",
    "\n",
    "Save this as `mean_image`. Use the code below to plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "ax.imshow(mean_image.reshape((32,32,3)).astype('uint8')) # visualize the mean image\n",
    "print(\"so beautiful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtract this mean image from train, validation, and test data. It is important that we use the same preprocessing on all of the data. Again, this \"centers\" our data. You can use an augmented update:\n",
    "```python\n",
    "x -= mean_image\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `Tensor`, `dense` and `multiclass_hinge` from `my_grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are dealing with much larger pieces of data than in the spiral data, we will only be training on \"batches\" of our training data. We will be using a batch size of 200. The following code will, for each iteration of training, draw a random batch of data of your training data/labels, of size 200:\n",
    "\n",
    "```python\n",
    "for i in range(400):\n",
    "    mask = np.random.choice(len(x_train), size=200, replace=False)\n",
    "    x_batch = x_train[mask]\n",
    "    y_batch = y_train[mask]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the validation set to tune hyperparameters (regularization strength and learning rate). You should experiment with different ranges for the learning rates and regularization strengths; if you are careful you should be able to get a classification accuracy of about 0.4 on the validation set.\n",
    " \n",
    "Generate a list of learning rates and regularization strengths to assess, using the validation set. `[1e-6,1e-7,1e-8]` are reasonable guesses at learning rates. `[1e5,1e4,1e3]` are reasonable starting guesses at regularization strengths.\n",
    "\n",
    "We want to test the various combinations of learning rate and regularization strength, and see which hyper-parameter values performs the best on our validation set.\n",
    "\n",
    "`itertools.product` is a good way to generate all pairs of parameters. You may also want to add a bit of random skew to your parameters, so that you aren't searching on a rectangular grid.\n",
    "\n",
    "You will create a dictionary `results`, whose keys are the tuple `(learning_rate, reg_strength)`, and whose values are `(train_acc, val_acc)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "results = {}\n",
    "best_val = -1   # The highest validation accuracy that we have seen so far.\n",
    "best_weights = None # W.data array that achieved the highest validation rate.\n",
    "best_losses = []  # list of loss values measured during best training session\n",
    "best_accs = []  # list of validation accuracies measured during best training session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for rate, reg in your_various_rate_reg_pairs:\n",
    "    # Initialize W with\n",
    "    W_shape = ???\n",
    "    W = Tensor(0.001 * np.random.randn(*W_shape))\n",
    "    \n",
    "    # Initialize b with\n",
    "    b_shape = ???\n",
    "    b = Tensor(np.zeros(b_shape, dtype=W.dtype))\n",
    "    \n",
    "    losses = []  # will store loss for each training iteration\n",
    "    accuracies = []  # will store training accuracy for each training iteration\n",
    "    \n",
    "    # don't train for very long - we are testing several hyper parameter\n",
    "    # configurations\n",
    "    for it in range(400):\n",
    "        x_batch = ???\n",
    "        y_batch = ???\n",
    "        \n",
    "        train_predictions = ???\n",
    "        loss = ???  # hinge loss with regularization\n",
    "        loss.backward()\n",
    "        \n",
    "        # !!! Update model parameters using gradient descent with!!!\n",
    "        ### with the correct learning rate\n",
    "        \n",
    "        loss.null_gradients()  # this is super important!!\n",
    "        \n",
    "        train_accuracy = ??? # the accuracy for this training batch\n",
    "        accuracies.append(train_accuracy)\n",
    "        losses.append(loss.data.item())\n",
    "       \n",
    "    # Training is complete for this hyperparameter configuration\n",
    "    \n",
    "    # Use your trained model parameters to compute the predicted scores\n",
    "    # on the training data. Use this to compute the training-accuracy.\n",
    "    # save this to `train_acc`\n",
    "    \n",
    "    # Use your trained model parameters to compute the predicted scores\n",
    "    # on the validation data. Use this to compute the training-accuracy.\n",
    "    # save this to `val_acc`\n",
    "\n",
    "    results[(rate, reg)] = (train_acc, val_acc)\n",
    "\n",
    "    if best_val < val_acc:\n",
    "        best_loss = losses\n",
    "        best_accs = accuracies\n",
    "        best_val = val_acc\n",
    "        best_train = train_acc\n",
    "        best_weights = W.data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will plot the evolution of your training loss and accuracy\n",
    "# during the session using your best hyperparameters\n",
    "\n",
    "fig,(ax,ax2) = plt.subplots(nrows=2)\n",
    "ax.plot(best_loss)\n",
    "ax2.plot(best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un-comment and run this code if you want to save your dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"cifar-10_exp.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(resuls, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Your Various Hyperparameters\n",
    "Below, we plot the various hyperparameters that you tried out. The color\n",
    "of the points indicate the training and validation accuracies. Notice that we are **not** computing the test-accuracy. We should only evaluate this once we have our final, fully trained model with our optimal hyperparameters! This is the only way we can rely on our test-accuracy as reflecting the true, unbiased performance of our model!\n",
    "\n",
    "Notice that these plots are on a log-10 scale. Look at the distribution of the hyperparameters that you tested, and their colors. Do you see a region that seems to have more-optimal hyperparameter values? Feel free to go back and rerun the above block on additional hyperparameters. **DO NOT** reset your `results` dictionary - you want to keep these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cross-validation results\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "x_scatter = [math.log10(x[0]) for x in results]\n",
    "y_scatter = [math.log10(x[1]) for x in results]\n",
    "\n",
    "# plot training accuracy\n",
    "marker_size = 100\n",
    "colors = [results[x][0] for x in results]\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=cm.viridis)\n",
    "plt.colorbar()\n",
    "# plt.xlabel('log learning rate')\n",
    "plt.ylabel('log regularization strength')\n",
    "plt.title('CIFAR-10 training accuracy')\n",
    "\n",
    "# plot validation accuracy\n",
    "colors = [results[x][1] for x in results] # default size of markers is 20\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors,  cmap=cm.viridis)\n",
    "plt.colorbar()\n",
    "plt.xlabel('log learning rate')\n",
    "plt.ylabel('log regularization strength')\n",
    "plt.title('CIFAR-10 validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training your model with optimal hyperparameters\n",
    "Using your final hyperparameters, reinitialize your model weights, and train it from scratch using these optimal hyperparameters. Train for longer though - about 3000 iterations. Record the loss and batch-accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to visualize what the model learned! We will reshape $W$ so that each column is a $(32, 32, 3)$ image. Remember. Each column of $W$ is trying to learn what the \"canonical image\" is for a car, or frog, etc, depending on which column you look at.\n",
    "\n",
    "Depending on your choice of learning rate and regularization strength, these may or may not be nice to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = W.data  # pass the numpy-array of your trained model weights here\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "\n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your model's performance on the test data\n",
    "Finally! We can measure the accuracy of our model, making predictions on the test data set. Because Our model has never \"seen\" this data - it was not trained on it, nor did we consult it to pick our hyperparameters. Thus, this reflects the \"real world\" performance of our model on pictures it has never encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
